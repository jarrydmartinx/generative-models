{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Variational Autoencoder with Sonnet and TensorFlow Datasets.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rDsZhppENtuZ",
        "WK51D3GFPlGw",
        "amKVpDLUaSrr"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jarrydmartinx/generative-models/blob/master/variational-autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZemq6em6a7c",
        "colab_type": "text"
      },
      "source": [
        "# Variational Autoencoder with Sonnet and TensorFlow Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2Dx3KxM7Ct5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install\n",
        "! pip install -q plotnine"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sju0MAVe7Kho",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Imports\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import plotnine as gg\n",
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from collections import namedtuple\n",
        "\n",
        "from typing import Text, List, Tuple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25ILAonl8FlC",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2TTL-vQp0it",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Getting information about our data\n",
        "\n",
        "def get_metadata(dataset_name: Text):\n",
        "  dataset = tfds.load(dataset_name, split=tfds.Split.TRAIN)\n",
        "\n",
        "  # Extract the shape of the input images.\n",
        "  print('-----------Dataset metadata---------------')\n",
        "  image_shape = dataset.output_shapes['image']\n",
        "  print('Image shape: {}'.format(image_shape))  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf4R-wtp7lNm",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Loading and preparing our data\n",
        "\n",
        "def get_data(dataset_name: Text,\n",
        "             batch_size: int) -> tf.Tensor:\n",
        "\n",
        "  # Download the whole dataset, since we're doing unsupervised learning.\n",
        "  dataset = tfds.load(dataset_name, split=tfds.Split.ALL)\n",
        "\n",
        "  # Pipelining operations: repeat the dataset infinitely, then batch it.\n",
        "  dataset = dataset.repeat().batch(batch_size, drop_remainder=True)\n",
        "\n",
        "  # Make an iterator that we can use to draw batches of data.\n",
        "  iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "  # Make a op that returns the next batch of data when we run it.\n",
        "  data_batch = iterator.get_next()\n",
        "\n",
        "  # Extract the images from the data batch; cast to the dtype that TF expects\n",
        "  input_data = tf.cast(data_batch['image'], dtype=tf.float32)\n",
        "\n",
        "  return input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnDoy76JMrnF",
        "colab_type": "text"
      },
      "source": [
        "Run the cell below twice and you won't have all this annoying output clogging up your screen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PugzkOpU82T8",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "b522a3e9-d691-4741-a2e0-8cd97d5380fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "#@title Visualising our data\n",
        "\n",
        "def show_image(dataset_name: Text) -> None:\n",
        "  batch_size = 25\n",
        "  data_op = get_data(dataset_name, batch_size)\n",
        "\n",
        "  with tf.train.MonitoredSession() as sess:\n",
        "    data_batch = sess.run(data_op)\n",
        "\n",
        "  images = data_batch.squeeze(-1)\n",
        "  index = np.random.randint(batch_size - 1)\n",
        "  plt.imshow(images[index])\n",
        "\n",
        "show_image('mnist')\n",
        "get_metadata('mnist')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d72ef528900a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-d72ef528900a>\u001b[0m in \u001b[0;36mshow_image\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mdata_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMonitoredSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-bdd1d0fdfa36>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(dataset_name, batch_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Download the whole dataset, since we're doing unsupervised learning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m# Pipelining operations: repeat the dataset infinitely, then batch it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[0;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/registered.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, in_memory, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    316\u001b[0m   \u001b[0mas_dataset_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"read_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m   \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mas_dataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[0;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mas_dataset\u001b[0;34m(self, split, batch_size, shuffle_files, decoders, read_config, as_supervised, in_memory)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     )\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_single_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0;31m# Singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_build_single_dataset\u001b[0;34m(self, split, shuffle_files, batch_size, decoders, read_config, as_supervised, in_memory)\u001b[0m\n\u001b[1;32m    539\u001b[0m           \u001b[0mshuffle_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m           \u001b[0mdecoders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m           \u001b[0mread_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m       )\n\u001b[1;32m    543\u001b[0m       \u001b[0;31m# Auto-cache small datasets which are small enough to fit in memory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_as_dataset\u001b[0;34m(self, split, decoders, read_config, shuffle_files)\u001b[0m\n\u001b[1;32m    947\u001b[0m           \u001b[0msplit_infos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m           \u001b[0mread_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m           \u001b[0mshuffle_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m       )\n\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, name, instructions, split_infos, read_config, shuffle_files)\u001b[0m\n\u001b[1;32m    288\u001b[0m       )\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_read_instruction_to_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstructions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m   def read_files(\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 536\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 536\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36m_read_instruction_to_ds\u001b[0;34m(instruction)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \"\"\"\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_instruction_to_ds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m       \u001b[0mfile_instructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_file_instructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_infos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m       \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_instructions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_instructions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36mmake_file_instructions\u001b[0;34m(name, split_infos, instruction)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0minstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;31m# Create the absolute instruction (per split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m   \u001b[0mabsolute_instructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_absolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname2len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m   return _make_file_instructions_from_absolutes(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36mto_absolute\u001b[0;34m(self, name2len)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \"\"\"\n\u001b[1;32m    546\u001b[0m     return [_rel_to_abs_instr(rel_instr, name2len)\n\u001b[0;32m--> 547\u001b[0;31m             for rel_instr in self._relative_instructions]\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \"\"\"\n\u001b[1;32m    546\u001b[0m     return [_rel_to_abs_instr(rel_instr, name2len)\n\u001b[0;32m--> 547\u001b[0;31m             for rel_instr in self._relative_instructions]\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36m_rel_to_abs_instr\u001b[0;34m(rel_instr, name2len)\u001b[0m\n\u001b[1;32m    390\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname2len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     raise ValueError('Unknown split \"{}\". Should be one of {}.'.format(\n\u001b[0;32m--> 392\u001b[0;31m         split, list(name2len)))\n\u001b[0m\u001b[1;32m    393\u001b[0m   \u001b[0mnum_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname2len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0mfrom_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrel_instr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown split \"all\". Should be one of ['test', 'train']."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te5NGAkrPJBK",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENyNXhZWQVm1",
        "colab_type": "text"
      },
      "source": [
        "### The variational autoencoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZiyZzLtZ1zP",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://jaan.io/images/encoder-decoder.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLtxcrZDNizL",
        "colab_type": "text"
      },
      "source": [
        "### Making Variational Autoencoder Models with Sonnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcZQI-7SMDcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#HYPERPARAMETERSn_latent = 16\n",
        "batch_size = 100\n",
        "dataset_name = 'mnist'\n",
        "model_name = 'mlp_vae'\n",
        "learning_rate = 1e-3\n",
        "num_training_steps = 10000\n",
        "log_every = 20\n",
        "max_val = 10.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FUnOD2_DSzn",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#@title Encoder/Decoder Models\n",
        "\n",
        "def encode(input_data: tf.Tensor, \n",
        "           model_name: Text = 'mlp_vae',\n",
        "           n_latent: int = n_latent) -> tf.Tensor:\n",
        "# Encoder\n",
        "  \n",
        "  encoders = {\n",
        "      'mlp_vae': snt.Sequential([\n",
        "          snt.BatchFlatten(),\n",
        "          snt.nets.MLP([64, 32], activate_final=True)])\n",
        "  }\n",
        "  \n",
        "  embedding = encoders[model_name](input_data)\n",
        "  latent_mu = snt.Linear(output_size=n_latent)(embedding)\n",
        "  latent_log_var = snt.Linear(output_size=n_latent)(embedding)\n",
        "  \n",
        "  max_log_val = tf.cast(max_val, tf.float32)\n",
        "\n",
        "  \n",
        "  latent_log_var = tf.clip_by_value(latent_log_var,\n",
        "                                      clip_value_max=max_log_val,\n",
        "                                      clip_value_min=1e-5)\n",
        "\n",
        "  latent_var = tf.exp(latent_log_var)\n",
        "  \n",
        "  return latent_mu, latent_var\n",
        "\n",
        "# Decoder\n",
        "# latent values is a sample from the latent space defined by mu and var above\n",
        "def decode(latent_values: tf.Tensor, \n",
        "           model_name: Text = 'mlp_vae',\n",
        "           batch_size: int = batch_size):\n",
        "  \n",
        "  mlp_decoder = snt.Sequential([\n",
        "      snt.nets.MLP([32, 64, 784]),\n",
        "      lambda x: tf.reshape(x, shape=[batch_size, 28, 28, 1])])\n",
        "\n",
        "  reconstruction = mlp_decoder(latent_values)\n",
        "  \n",
        "  return reconstruction\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDsZhppENtuZ",
        "colab_type": "text"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK51D3GFPlGw",
        "colab_type": "text"
      },
      "source": [
        "### The variational lower bound  $\\mathcal{L}(\\theta, \\phi; \\mathbf{x}^{(i)})$ on the marginal log-likelihood $\\log p_\\text{model}(\\mathbf{\\mathbf{x}^{(i)}};\\theta)$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Api5FE_4Mlww",
        "colab_type": "text"
      },
      "source": [
        "The marginal log-likelihood under our model for a single training sample $\\mathbf{x}^{(i)}$ can be rewritten as:\n",
        "\\begin{align}\n",
        "\\log p(\\mathbf{x}^{(i)}; \\mathbf{\\theta}) \\quad\n",
        "&= \\quad \\mathbb{E}_{q(z|x)}\\left[\\log p_\\theta(\\mathbf{x}^{(i)})\\right] \\\\\n",
        "&= \\quad \\mathbb{E}_{q(z|x)}\\left[\\log \\frac{p_\\theta(\\mathbf{x}^{(i)},\\mathbf{z})}{p_\\theta(\\mathbf{z}\\mid \\mathbf{x}^{(i)})}\\right] \\\\\n",
        "&= \\quad \\mathbb{E}_{q(z|\\mathbf{x})}\\left[\\log \\frac{p_\\theta(\\mathbf{x}^{(i)}, \\mathbf{z})\\ q_\\phi(\\mathbf{z} \\mid \\mathbf{x}^{(i)})}{q_\\phi(\\mathbf{z} \\mid \\mathbf{x}^{(i)})\\ p_\\theta(\\mathbf{z}\\mid \\mathbf{x}^{(i)})} \\right]\\\\\n",
        "&= \\quad \\mathbb{E}_{q(z|\\mathbf{x})}\\left[\\log \\frac{p_\\theta(\\mathbf{x}^{(i)},\\mathbf{z})}{q_\\phi(\\mathbf{z} \\mid \\mathbf{x}^{(i)})} + \\log \\frac{q_\\phi(\\mathbf{z} \\mid \\mathbf{x}^{(i)})}{p_\\theta(\\mathbf{z}\\mid \\mathbf{x}^{(i)})}\\right]\\\\\n",
        "&= \\quad \\mathbb{E}_{q(\\mathbf{z}|\\mathbf{x})}\\left[\\log \\frac{p_\\theta(\\mathbf{x}^{(i)}, \\mathbf{z})}{q_\\phi(\\mathbf{z} \\mid \\mathbf{x}^{(i)})}\\right] +  \\mathbb{E}_{q(z|\\mathbf{x})}\\left[\\log \\frac{q_\\phi(\\mathbf{z} \\mid \\mathbf{x}^{(i)})}{ p_\\theta(\\mathbf{z}\\mid \\mathbf{x}^{(i)})}\\right] \\\\\n",
        "&= \\underbrace{\\mathcal{L}(\\theta, \\phi ; \\mathbf{x}^{(i)})}_\\text{Var. lower bound on marg. log-likelihood of $\\mathbf{x}^{(i)}$} + \\qquad   \\underbrace{D_{KL} (q_\\phi(z \\mid \\mathbf{x}^{(i)}) \\Vert p_\\theta(\\mathbf{z}\\mid \\mathbf{x}^{(i)}))}_\\text{KL bw approximate and 'true' model posterior ($\\theta$-dependent)} \n",
        "\\end{align}\n",
        "\n",
        "We can write the evidence lower bound (ELBO) as:\n",
        "\\begin{align}\n",
        "\\log p_\\theta(\\mathbf{x}^{(i)}) \n",
        "&\\geq \\quad \\mathcal{L}(\\theta, \\phi; \\mathbf{x}^{(i)}) \\\\\n",
        "&= \\quad \\mathbb{E}_{q(z\\mid\\mathbf{x}^{(i)})}\\left[\\log \\frac{p(\\mathbf{x}^{(i)}, z)}{q(z|\\mathbf{x}^{(i)})}\\right] \\\\\n",
        "&= \\quad \\mathbb{E}_{q_\\phi (z\\mid \\mathbf{x}^{(i)})}\\big\\{\\log p_\\theta (\\mathbf{x}^{(i)}, z) -\\log q_\\phi (z \\mid \\mathbf{x}^{(i)}) \\big\\} \\\\\n",
        "&= \\quad \\underbrace{\\mathbb{E}_{q_\\phi (z\\mid \\mathbf{x}^{(i)})}\\big\\{\\log p_\\theta (\\mathbf{x}^{(i)}, z) \\big\\}}_\\text{Exp. complete data log-likelihood} \\qquad +  \\underbrace{H(q_\\phi (z\\mid \\mathbf{x}^{(i)}))}_\\text{Entropy of approx. posterior $q$}\\\\\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "For our purposes, we will rewrite this equation in a form that best reflects the way VAEs compute an estimate of the (negative) ELBO:\n",
        "\\begin{align}\n",
        "\\boxed{- \\mathcal{L}(\\theta, \\phi; x^{(i)}) = \\qquad \\underbrace{- \\mathbb{E}_{q_\\phi(z \\mid x^{(i)})} \\big\\{\\log p_\\theta (x^{(i)}\\mid z) \\big\\}}_\\text{exp'd recontruction error}  \\qquad + \\underbrace{D_{KL}(q_\\phi (z\\mid x^{(i)}) \\Vert p_\\theta(z))}_{\\text{regularizes $\\phi$ so approx. posterior $q_\\phi$ is close to prior $p_\\theta$}}}\n",
        "\\end{align}\n",
        "\n",
        "(it's nice because it's equivalent to maximising the expectation pictured above, but with respect to q(z|x) instead of p(z), with a KL correction term which penalises how far q(z|x) is from p(z))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6gGLY2xQoWL",
        "colab_type": "text"
      },
      "source": [
        "### Estimating the ELBO $\\mathcal{L}(\\theta, \\phi; x^{(i)})$ and its gradients\n",
        "* VAEs train by maximizing the evidence lower bound (ELBO) on the marginal log-likelihood, which is an expectation taken against $q_\\phi (z'\\mid x)$. In practice we often only compute the single sample Monte Carlo estimate of this expectation:\n",
        "\\begin{align}\n",
        "&\\mathbb{E}_{q_\\phi (\\mathbf{z}^{(i)}\\mid \\mathbf{x}^{(i)})}\\big\\{\\log p_\\theta (\\mathbf{x}^{(i)}, \\mathbf{z}^{(i)}) -\\log q_\\phi (\\mathbf{z}^{(i)} \\mid \\mathbf{x}^{(i)}) \\big\\} \\\\\n",
        "\\approx \\quad &\\frac{1}{L}\\sum_{l = 1}^{L} \\log p_\\theta (\\mathbf{z}^{(i,l)}) + \\log p_\\theta (\\mathbf{x}^{(i)} \\mid \\mathbf{z}^{(i,l)}) - \\log q_\\phi (\\mathbf{z}^{(i,l)} \\mid \\mathbf{x}^{(i)}) \\qquad \\mathbf{z}^{(i,l)}  \\sim q_\\phi (\\mathbf{z}\\mid \\mathbf{x}^{(i)}) \\\\\n",
        "\\approx \\quad &\\log p_\\theta (\\mathbf{z}^{(i,l)}) + \\log p_\\theta (\\mathbf{x}^{(i)} \\mid \\mathbf{\\mathbf{z}}^{(i,l)}) - \\log q_\\phi (\\mathbf{z}^{(i,l)} \\mid \\mathbf{x}^{(i)}) \\qquad \\mathbf{z}^{(i,l)}  \\sim q_\\phi (\\mathbf{z} \\mid \\mathbf{x}^{(i)})\n",
        "\\end{align}\n",
        "\n",
        "If the KL term can be integrated analytically, we need only compute an estimate of the expected reconstruction error.\n",
        "  * The single sample Monte Carlo estimate of the expected reconstruction error is:\n",
        "$$\\log p(\\mathbf{x}^{(i)}| z') \\qquad z'\\sim q_{\\phi}(z|\\mathbf{x}^{(i)})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG0c5NQTQHSI",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6372aHc8PoQA",
        "colab_type": "text"
      },
      "source": [
        "### Training our model with the ELBO Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zyy6_gARXfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a container for the images that our trained models will reconstruct\n",
        "ImageReconstructions = namedtuple('ImageReconstructions', \n",
        "                                  ['true_images', \n",
        "                                   'recon_images', \n",
        "                                   'latent_values'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlTUWmqxN0Mm",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Our train function\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Get our image data\n",
        "input_data = get_data(dataset_name, batch_size)\n",
        "\n",
        "latent_mu, latent_var = encode(input_data, model_name)\n",
        "\n",
        "latent_sigma = tf.sqrt(latent_var)\n",
        "\n",
        "noise = tf.random_normal(shape=latent_mu.shape)\n",
        "\n",
        "print('Latent_sigma.shape: {}, Latent_mu.shape: {}'.format(latent_sigma.shape,\n",
        "                                                          latent_mu.shape))\n",
        "#@TODO(jarryd@google.com): CHECK THIS HAS A BATCH SIZE!!, you should be \n",
        "# sampling for each, not trying to get the whole batch to fit to a sample\n",
        "\n",
        "latent_value = noise * (latent_sigma * 0.5) + latent_mu\n",
        "\n",
        "output = decode(latent_value)\n",
        "\n",
        "# The reconst. loss term in the ELBO loss function of our VAE\n",
        "print('Output Shape: {}'.format(output.shape))\n",
        "reconstruction_loss = tf.reduce_mean((output - input_data) ** 2)\n",
        "\n",
        "# The KL term in the ELBO loss function of our VAE\n",
        "# kl_loss = tf.constant(0., dtype=tf.float32)\n",
        "kl_loss = 0.5 * (latent_var + latent_mu ** 2\n",
        "                 - tf.log(latent_var) - 1)  # [B, L]\n",
        "kl_loss = tf.reduce_sum(kl_loss, axis=-1)  # [B]\n",
        "kl_loss = tf.reduce_mean(kl_loss)  # []\n",
        "\n",
        "# This is the ELBO loss for which we will compute gradients\n",
        "loss_op = reconstruction_loss + kl_loss\n",
        "\n",
        "# Pick an optimizer; Adam is a common choice that often works well\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "# This op computes and applies our gradients for the batch (takes one sgd step)\n",
        "sgd_op = optimizer.minimize(loss_op)\n",
        "\n",
        "\n",
        "num_samples = batch_size\n",
        "\n",
        "# Sampling stuff, generative stuff\n",
        "sample_latents = tf.placeholder(tf.float32, shape=(num_samples, n_latent))\n",
        "sample_images = decode(sample_latents, batch_size=num_samples)\n",
        "\n",
        "#@TODO(jarryd@google.com): You need to get the real latent for EVERY image that \n",
        "# you're outputting \n",
        "\n",
        "# We need an open session to run our sgd and loss ops\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer()) # Initialize our variables\n",
        "\n",
        "results = []\n",
        "images = {}\n",
        "print('----------------------------------------------')\n",
        "print('Training {} model on the {} dataset...'.format(model_name, dataset_name))\n",
        "print_every = num_training_steps/10\n",
        "\n",
        "# Training Loop\n",
        "for step in range(0, num_training_steps + 1):\n",
        "  sess.run(sgd_op)\n",
        "\n",
        "  if step % log_every == 0:\n",
        "    loss, kl, recon_loss = sess.run([loss_op, kl_loss, reconstruction_loss])\n",
        "    result = {\n",
        "        'step': step,\n",
        "        'loss': loss,\n",
        "    }\n",
        "    results.append(result)\n",
        "\n",
        "  if step % print_every == 0:\n",
        "    print('Iteration: {}, Loss: {}, KL: {}, Recon: {}'.format(step,\n",
        "                                                              loss,\n",
        "                                                              kl, \n",
        "                                                              recon_loss))\n",
        "\n",
        "true_images, latent_values, recons = sess.run([input_data, latent_value, output])\n",
        "print(latents.shape)\n",
        "images = ImageReconstructions(true_images=true_images.squeeze(-1), \n",
        "                              recon_images=recons.squeeze(-1),\n",
        "                              latent_values=latent_values)\n",
        "\n",
        "ims = sess.run([sample_images], \n",
        "               feed_dict={sample_latents: images.latent_values}).squeeze()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QQVDcQz3a0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ims = sess.run(sample_images, feed_dict={sample_latents: images.latent_values}).squeeze()\n",
        "# ims = sample(feed_dict={sample_latents: images.latent_values[:10]}).squeeze()\n",
        "\n",
        "\n",
        "ims.shape\n",
        "fig, axarray = plt.subplots(2, 4)\n",
        "i = 0\n",
        "for row in range(2):\n",
        "  for col in range(4):\n",
        "    axarray[row, col].imshow(ims[i])\n",
        "    i += 1\n",
        "    \n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8g1EIotmNaa",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Collecting our results\n",
        "\n",
        "datasets = ['mnist', 'fashion_mnist']\n",
        "models = ['mlp_vae']\n",
        "batch_size = 25\n",
        "num_steps = 2000\n",
        "\n",
        "results = pd.DataFrame()\n",
        "images = {}\n",
        "\n",
        "for dataset in datasets:\n",
        "  images[dataset] = {}\n",
        "  \n",
        "  for model in models:\n",
        "    result, recon_images = train_vae(dataset, \n",
        "                                     model, \n",
        "                                     num_training_steps=num_steps,\n",
        "                                     batch_size = batch_size)\n",
        "    result['dataset'] = dataset\n",
        "    result['model'] = model\n",
        "    \n",
        "    results = pd.concat([results, result])\n",
        "    images[dataset][model] = recon_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td82_SNLpWDj",
        "colab_type": "text"
      },
      "source": [
        "## Plotting the training loss and viewing the reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xw9xGTVvn7g",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Plotting the training loss for each model/dataset\n",
        "\n",
        "p = (gg.ggplot(results)\n",
        "     + gg.aes(x='step', y='loss', color='model')\n",
        "     + gg.theme(figure_size=(8, 4))\n",
        "     + gg.facet_wrap('dataset')\n",
        "     + gg.lims(x=(0, 2000))\n",
        "     + gg.geom_line()\n",
        "    )\n",
        "\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usyCFyCFy4rw",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Viewing the Generated Images\n",
        "\n",
        "num_combinations = len(datasets) * len(models)\n",
        "fig, axarray = plt.subplots(1, num_combinations)\n",
        "fig.set_figwidth(14)\n",
        "fig.set_figheight(7)\n",
        "\n",
        "column = 0\n",
        "rand_idx = np.random.randint(batch_size - 1)\n",
        "\n",
        "for dataset in datasets:\n",
        "  for model in models:\n",
        "    axarray[column].set_title('Dataset: {}, Model: {}'.format(dataset, model))\n",
        "    axarray[column].imshow(images[dataset][model].recon_images[rand_idx])\n",
        "    column += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjkzNJRG3lcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = np.random.randint(99)\n",
        "\n",
        "plt.imshow(images.true_images[idx])\n",
        "plt.show()\n",
        "plt.imshow(images.recon_images[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amKVpDLUaSrr",
        "colab_type": "text"
      },
      "source": [
        "## Playground\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsJOAomc0yB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kept_images = images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eJ7iGTfaVTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# except tf.errors.InvalidArgumentError:\n",
        "#   var = tf.clip_by_value(tf.exp(log_var), \n",
        "#                          clip_value_min=0., \n",
        "#                          clip_value_max=tf.float32.max)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}